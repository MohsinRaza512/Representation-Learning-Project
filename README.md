# Representation-Learning-Project

This repository contains the code, data, and results for my project on **fine-tuning and evaluating the Segment Anything Model (SAM-Med)** for medical image segmentation using the **22-Heart dataset**.  
The work investigates how different prompt types (point, box, both) affect segmentation performance on smaller dataset, measured by **Dice coefficient** and **HD95 boundary distance**.

---

## ğŸ“‚ Repository Structure

```
Representation-Learning-Project/
â”‚
â”œâ”€â”€ My_contribution/                     # Custom scripts and experiments
â”‚   â”œâ”€â”€ fine_tune_sam_heart.py                   # Fine-tunes SAM-Med on the 22-Heart dataset
â”‚   â”œâ”€â”€ prompt_type_comparison.py                # Evaluates model with different prompts
â”‚   â”œâ”€â”€ prompt_type_comparison_debug.py          # Extended/debug evaluation (per-threshold outputs)
â”‚   â”œâ”€â”€ plot_prompt_type_comparison.py           # Generates summary plots (Dice & HD95)
â”‚   â”œâ”€â”€ plot_prompt_type_comparison_extended.py  # Extended plots per threshold & per prompt type
â”‚   â”œâ”€â”€ visualize_prompt_type_comparison.py      # Bar plots for prompt efficiency comparison
â”‚   â”œâ”€â”€ visualize_prompt_robustness_heatmaps.py  # Heatmaps for prompt robustness
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                                # Dataset and pre-computed embeddings
â”‚   â””â”€â”€ precompute_vit_b/test/22_Heart/*.npz
â”‚
â”œâ”€â”€ data_infor_json/                     # Dataset metadata/configuration files
â”‚
â”œâ”€â”€ results/                             # Experimental outputs
â”‚   â”œâ”€â”€ prompt_type_comparison_heart/
â”‚   â”‚   â”œâ”€â”€ original_thr*/                # Results from baseline SAM-Med
â”‚   â”‚   â”œâ”€â”€ finetuned_epoch*/             # Results from fine-tuned SAM-Med (epochs 1â€“10)
â”‚   â”‚   â”œâ”€â”€ summary.csv                   # Aggregated averages across all experiments
â”‚   â”‚   â”œâ”€â”€ plots/                        # Summary plots (Dice & HD95 comparisons)
â”‚   â”‚   â””â”€â”€ plots_extended/               # Extended plots (per threshold & per prompt type)
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md                            # Project overview and instructions
```

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- PyTorch (with CUDA if available)
  Trained on HPC Server with 4x GPU

### Running the Code

### 1. Fine-tune the model
```bash
python My_contribution/fine_tune_sam_heart.py
```

### 2. Evaluate prompt types
- Standard evaluation:
  ```bash
  python My_contribution/prompt_type_comparison.py
  ```
- Extended/debug evaluation (per-threshold CSVs):
  ```bash
  python My_contribution/prompt_type_comparison_debug.py
  ```

### 3. Generate visualizations
- Summary plots (Dice & HD95 averages):
  ```bash
  python My_contribution/plot_prompt_type_comparison.py
  ```
- Extended plots (per-threshold, per-prompt type):
  ```bash
  python My_contribution/plot_prompt_type_comparison_extended.py
  ```
- Heatmaps for robustness:
  ```bash
  python My_contribution/visualize_prompt_robustness_heatmaps.py
  ```
- Prompt efficiency comparison:
  ```bash
  python My_contribution/visualize_prompt_type_comparison.py
  ```

Results (Dice, HD95, and plots) will be saved automatically in the `results/` folder.

---

## ğŸ“Š Key Results

- **Box and Both prompts**: Achieved highest Dice scores (~0.75-0.80) after fine-tuning.  
- **Point prompts**: Improved modestly (~0.48), but boundary precision (HD95) remained weaker.  
- **Takeaway**: Fine-tuning improved overlap accuracy but did not consistently improve boundary stability with limited data.

Plots and CSVs are available in:  
- `results/prompt_type_comparison_heart/plots/`  
- `results/prompt_type_comparison_heart/plots_extended/`

---

## ğŸ¤ Contribution

This repository is part of a university research project. External contributions are not expected, but feedback is welcome via GitHub issues.

---

## ğŸ“œ License

This project is released for **academic purposes only**.  
Model checkpoints (SAM-Med) are subject to their original licenses.

---
